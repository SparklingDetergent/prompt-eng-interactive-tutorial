# 第8章: ハルシネーション（幻覚）の回避

このドキュメントは `Anthropic 1P/08_Avoiding_Hallucinations.ipynb` の主要な概念を日本語で説明するものです。

## レッスン

悪い知らせがあります：**Claudeは時々「ハルシネーション（幻覚）」を起こし、真実でない、または正当化されない主張をすることがあります。** 良い知らせは、ハルシネーションを最小限に抑えるために使用できるテクニックがあるということです。

以下では、これらのテクニックのいくつかを説明します：
- Claudeに質問の答えがわからないと言う選択肢を与える
- Claudeに回答する前に証拠を見つけるよう依頼する

しかし、**ハルシネーションを回避する方法は多数あり**、このコースで既に学んだ多くのテクニックも含まれます。Claudeがハルシネーションを起こした場合、複数のテクニックを試してClaudeの精度を向上させてください。

### ハルシネーションとは？
ハルシネーションとは、大規模言語モデル（LLM）が、訓練データや提供された文脈情報に基づいていない、事実と異なる情報や誤った情報を生成してしまう現象を指します。モデルが「知ったかぶり」をして、不確かな情報を確信を持って述べてしまうようなものです。これは、モデルができるだけ役立とうとする性質から生じることがあります。

### 例

**例1: 一般的な事実に関する質問（最も重いカバ）**

初期プロンプト：
```
User: 史上最も重いカバは誰ですか？
```
Claudeの応答：（存在しないカバの名前や体重を「ハルシネーション」する可能性がある。例えば、「最も重いカバは体重6000kgの『ビッグバーサ』でした」など。）

この問題を解決するために試みることができるのは、「**Claudeに逃げ道を与える**」ことです。つまり、Claudeに、答えることを辞退してもよい、または確信を持って答えを知っている場合にのみ答えるように伝えます。

改善されたプロンプト：
```
User: 史上最も重いカバは誰ですか？確信を持って答えを知っている場合にのみ答えてください。
```
Claudeの応答：（「史上最も重いカバに関する具体的な記録は持ち合わせていません。」など、正直に不明であることを示す可能性が高くなる。）

**例2: 文書からの情報抽出（Matterport社の加入者数）**

以下のプロンプトでは、ユーザーの質問にほとんど関係ないが、わずかに関連性のある「おとり情報」を含む長い文書をClaudeに与えます。**プロンプティングの助けなしでは、Claudeはおとり情報に引っかかり**、2020年5月31日時点のMatterport社の加入者数について誤った「ハルシネーション」の回答をします。

（注：次の章で学ぶように、質問はテキストや文書の*後*、一番下に置くのがベストプラクティスですが、ここではプロンプトを読みやすくするために一番上に置いています。）

初期プロンプト（文書の前に質問）：
```
<question>2020年5月31日時点でのMatterportの加入者数は何人でしたか？</question>
以下の文書を読んでください。その後、<answer>タグ内に簡単な数値の答えを書いてください。

<document>
[Matterport SEC提出書類 10-K 2023 の長文テキスト...]
文書内には「2022年12月31日時点で、当社の加入者ベースは約39%増の701,000人以上（2021年12月31日時点の503,000人から増加）」という記述はあるが、2020年5月31日時点の正確な数値はない。
</document>
```
Claudeの応答：（文書中の別の時点の数値や、不正確な数値を「ハルシネーション」する可能性がある。）

これを修正する方法は？ 長文読解におけるハルシネーションを減らす良い方法は、**Claudeにまず証拠を集めさせる**ことです。

この場合、**Claudeにまず関連する引用を抽出し、次にそれらの引用に基づいて回答するよう指示します。** これにより、Claudeは引用が質問に答えていないことに正しく気づくようになります。

改善されたプロンプト：
```
<question>2020年5月31日時点でのMatterportの加入者数は何人でしたか？</question>
以下の文書を読んでください。次に、<scratchpad>タグ内に、文書から最も関連性の高い引用を抜き出し、それがユーザーの質問に答えているか、詳細が不足しているかを検討してください。その後、<answer>タグ内に簡単な数値の答えを書いてください。

<document>
[Matterport SEC提出書類 10-K 2023 の長文テキスト...]
</document>
```
Claudeの応答（期待される形式）：
```
<scratchpad>
関連する引用を探しましたが、文書中には2020年5月31日時点でのMatterportの正確な加入者数を示す情報は見つかりませんでした。文書には「2022年12月31日時点で、当社の加入者ベースは約39%増の701,000人以上（2021年12月31日時点の503,000人から増加）」や「当社の加入者数は2018年12月31日から2022年12月31日までに約49倍に増加しました」という記述がありますが、特定の2020年5月31日の数値はありません。
</scratchpad>
<answer>提供された文書には、2020年5月31日時点でのMatterportの加入者数に関する具体的な情報は見当たりませんでした。</answer>
```
このように、まず証拠（引用）を探させ、その証拠に基づいて判断させることで、Claudeは情報が存在しないことを認識しやすくなります。

### その他のテクニックと考慮事項

- **温度（Temperature）を下げる:**
  APIの`temperature`パラメータは、応答の創造性（ランダム性）を制御します（0から1の範囲）。0は最も一貫性があり、1はより予測不可能で標準化されていません。温度を0に近づけると、ハルシネーションの可能性が減る傾向があります（この章の例ではデフォルトで0が使用されています）。

- **他のプロンプティング技術の組み合わせ:**
  明確な指示、ロールプロンプティング、ステップバイステップ思考など、これまでに学んだ他の多くの技術もハルシネーションの低減に役立ちます。

## まとめ
この章では、Claudeが事実に基づかない情報（ハルシネーション）を生成する問題と、それを軽減するための主要な戦略を学びました。
1.  **「わからない」という選択肢を与える:** Claudeに、情報がない場合や確信が持てない場合は、その旨を表明することを許可します。
2.  **証拠に基づく回答:** 特に文書からの質疑応答（Q&A）の場合、まず関連情報を引用させ、その引用のみに基づいて回答するように指示します。これにより、回答が提供された文脈にしっかりと基づくようになります。
これらのテクニックは、Claudeの回答の信頼性を高めるのに役立ちます。
